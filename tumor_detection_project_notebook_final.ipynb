{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43ef578",
   "metadata": {},
   "source": [
    "# Tumor Detection Project Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc5aa6",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "This project requires TensorFlow for building and training the neural network, OpenCV for image processing, matplotlib and seaborn for visualizations, and scikit-learn for evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following line if any of these libraries are not installed\n",
    "!pip install tensorflow opencv-python matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04329a",
   "metadata": {},
   "source": [
    "## Imports and Configuration\n",
    "The code begins by importing necessary libraries and setting fixed seeds for reproducibility. All relevant modules from the src folder are imported to handle data operations, model construction, training callbacks, and evaluation utilities. The directories for raw and processed data are defined along with the image size, batch size, and split ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9de535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from src.data import split_data, load_datasets\n",
    "from src.model import build_model, compute_class_weights, get_callbacks\n",
    "from src.evaluate import plot_metrics, evaluate_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "RAW_DIR = 'data_set'\n",
    "PROC_DIR = 'data_set'\n",
    "CATEGORIES = ['yes', 'no']\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c94bac",
   "metadata": {},
   "source": [
    "## Data Inspection and Visualization\n",
    "The first step is to inspect the raw images to understand their dimensions and to display representative samples. This step ensures that resizing is necessary and that there are no corrupted files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6897d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "image_dims = {}\n",
    "for cat in CATEGORIES:\n",
    "    folder = os.path.join(RAW_DIR, cat)\n",
    "    for fname in os.listdir(folder):\n",
    "        img = plt.imread(os.path.join(folder, fname))\n",
    "        image_dims[f\"{cat}/{fname}\"] = img.shape\n",
    "df_dims = pd.DataFrame.from_dict(\n",
    "    image_dims,\n",
    "    orient='index',\n",
    "    columns=['height', 'width', 'channels']\n",
    ")\n",
    "display(df_dims.describe())\n",
    "print(f\"Total images: {len(df_dims)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1316dcfa",
   "metadata": {},
   "source": [
    "The summary statistics show the variation in image height and width and confirm that all images have three color channels. The sample images displayed below illustrate typical examples from each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3331c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "for ax, cat in zip(axes, CATEGORIES):\n",
    "    path = os.path.join(RAW_DIR, cat, os.listdir(os.path.join(RAW_DIR, cat))[0])\n",
    "    img = plt.imread(path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(cat)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef855b3",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "The dataset is split into training, validation, and test sets using an eighty, fifteen, and five percent ratio respectively. This split allows the model to learn from the training set, tune parameters on the validation set, and finally be assessed on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(\n",
    "    source_dir=RAW_DIR,\n",
    "    dest_dir=PROC_DIR,\n",
    "    categories=CATEGORIES,\n",
    "    train_pct=TRAIN_RATIO,\n",
    "    val_pct=VAL_RATIO,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f06d3",
   "metadata": {},
   "source": [
    "## Loading Datasets\n",
    "The TensorFlow data pipeline is then used to load images from the processed directories. Training and validation datasets are shuffled to improve model robustness, and the batch size parameter controls the number of samples processed before updating the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1052301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, class_names = load_datasets(\n",
    "    PROC_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Classes detected: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce491a5f",
   "metadata": {},
   "source": [
    "## Model Building and Training\n",
    "The model architecture uses a MobileNetV2 backbone pre-trained on ImageNet to extract features. Data augmentation layers randomly flip, rotate, zoom, translate, and adjust contrast to reduce overfitting. Dropout and L2 regularization are included for further generalization benefits. Training uses the Adam optimizer with binary crossentropy and applies class weights to address any imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30614e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    dropout_rate=0.6,\n",
    "    l2_rate=1e-4\n",
    ")\n",
    "cw = compute_class_weights(train_ds)\n",
    "print(f\"Class weights: {cw}\")\n",
    "callbacks = get_callbacks(patience=12)\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=cw\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df44e6",
   "metadata": {},
   "source": [
    "## Training Metrics Interpretation\n",
    "The accuracy curves for both training and validation data show how well the model learns over epochs. A steady increase in both curves with minimal divergence indicates good generalization. The loss curves complement the accuracy information by showing how the prediction error evolves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a10491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c15e6b",
   "metadata": {},
   "source": [
    "## Detailed Evaluation\n",
    "The evaluation phase generates classification reports and confusion matrices for the train, validation, and test sets. Precision and recall metrics for each class reveal whether the model tends to miss tumors or produce false alarms. The confusion matrices visually display the counts of correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, train_ds, class_names, title='Train')\n",
    "evaluate_model(model, val_ds, class_names, title='Validation')\n",
    "evaluate_model(model, test_ds, class_names, title='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd71bf5",
   "metadata": {},
   "source": [
    "## Save and Inference\n",
    "The final model is saved in HDF5 format for deployment or further use. A helper function loads and preprocesses a new image and the model then returns a probability score. The score above or below 0.5 is interpreted as presence or absence of a tumor, and these probabilities can be adjusted for specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973967",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "MODEL_PATH = 'models/best_model.keras'\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"Model saved at {MODEL_PATH}\")\n",
    "\n",
    "def load_and_preprocess(img_path, img_size):\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    arr = image.img_to_array(img) / 255.0\n",
    "    return np.expand_dims(arr, axis=0)\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "img_path = 'images.jpg'\n",
    "x = load_and_preprocess(img_path, IMG_SIZE)\n",
    "pred = float(model.predict(x)[0][0])\n",
    "label = 'Tumor' if pred > 0.5 else 'No Tumor'\n",
    "print(f\"Prediction score: {pred:.4f} leads to label {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32198174",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook has walked through each step of the tumor detection pipeline with clear explanations and interpretations. The design choices, training behavior, and evaluation results are all described in narrative form to highlight understanding and reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
